{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.9"
    },
    "colab": {
      "name": "Predictionbasedrecommander.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meenakshi25jan/Prediction-Based-Music-Recommandation/blob/main/Predictionbasedrecommander.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhip3iIwfrDi"
      },
      "source": [
        "# Prediction Based  System using Apache Spark and Python\n",
        "\n",
        "\n",
        "## Description\n",
        "\n",
        "In this project we are going to  create a recommender system that will prediction base recommend new musical singers to a user. This reommandation system works based on their listening history. This system Suggest different songs or musical singers to a user is important to many music streaming services, such as Spotify ,Pandora and Netflix. \n",
        "\n",
        "for creating the system we are using Spark and the collaborative filtering technique. \n",
        "## Datasets\n",
        "\n",
        "You will be using some publicly available song data from audioscrobbler, which can be found  given link(http://www-etud.iro.umontreal.ca/~bergstrj/audioscrobbler_data.html). \n",
        "The original data file `user_singer_data.txt` contained about 141,000 unique users, and 1.6 million unique singers. About 24.2 million usersâ€™ plays of singers are recorded, along with their count.\n",
        "\n",
        "\n",
        "The `singer_data.txt` file then provides a map from the canonical singer ID to the name of the singer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyd5lM_kfrEc"
      },
      "source": [
        "## Package Imports (Require for Recommandtion)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_Rzs6lsqfrEg"
      },
      "source": [
        "from pyspark.mllib.recommendation import *\n",
        "import random\n",
        "from operator import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VuLYGl6frE1"
      },
      "source": [
        "## Loading data\n",
        "\n",
        "Load the three datasets into RDDs and name them `singerData`, `singerAlias`, and `usersingerAData`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He92XFF3frE6"
      },
      "source": [
        "#Loading data into RDD\n",
        "singerData = sc.textFile(\"singer_data_small.txt\")\n",
        "singerAlias = sc.textFile(\"singer_alias_small.txt\")\n",
        "usersingerData = sc.textFile(\"user_singer_data_small.txt\")\n",
        "\n",
        "alias_data = singerAlias.collect()\n",
        "user_data = usersingerData.collect()\n",
        "singer_canonical_dict = {}\n",
        "user_list = []\n",
        "\n",
        "for line in alias_data:\n",
        "    singer_record = line.split(\"\\t\")\n",
        "    singer_canonical_dict[singer_record[0]] = singer_record[1]\n",
        "\n",
        "#Function to get canonical singer names\n",
        "def canonicalsingerID(line):\n",
        "    line = line.split(\" \")\n",
        "    \n",
        "    if line[1] in singer_canonical_dict:\n",
        "        return (int(line[0]),int(singer_canonical_dict[line[1]]),int(line[2]))\n",
        "    else:\n",
        "        return (int(line[0]),int(line[1]),int(line[2]))\n",
        "    \n",
        "#Getting canonical singer names        \n",
        "usersingerData = usersingerData.map(canonicalsingerID)\n",
        "\n",
        "#Creating allsingers dataset to be used later during model evaluation process\n",
        "allsingers = usersingerData.map(lambda x:(x[1])).collect()\n",
        "allsingers = list(set(allsingers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7Vo7RWffrE_"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "In the blank below, write some code that with find the users' total play counts. Find the three users with the highest number of total play counts (sum of all counters) and print the user ID, the total play count, and the mean play count (average number of times a user played an singer). Your output should look as follows:\n",
        "```\n",
        "User 1059637 has a total play count of 674412 and a mean play count of 1878.\n",
        "User 2064012 has a total play count of 548427 and a mean play count of 9455.\n",
        "User 2069337 has a total play count of 393515 and a mean play count of 1519.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1BQ5YW0frFE",
        "outputId": "26995ba5-39b5-4930-dcc8-067dfe28d64c"
      },
      "source": [
        "singer_data = singerAlias.collect()\n",
        "    \n",
        "user_play_count = {}\n",
        "user_count_number = {}\n",
        "\n",
        "for line in user_data:\n",
        "     user_record = line.split()\n",
        "     if user_record[0] in user_play_count:\n",
        "         user_play_count[str(user_record[0])] = user_play_count[user_record[0]] + int(user_record[2])\n",
        "         user_count_number[str(user_record[0])] = user_count_number[user_record[0]] + 1\n",
        "     else:\n",
        "         user_play_count[str(user_record[0])] = int(user_record[2])\n",
        "         user_count_number[str(user_record[0])] = 1\n",
        "top = 0\n",
        "maximum = 2\n",
        "\n",
        "for word, count in sorted(user_play_count.iteritems(), key=lambda (k,v): (v,k), reverse = True):\n",
        "     if top > maximum:\n",
        "        break\n",
        "     print 'User ' + str(word) + ' has a total play count of ' + str(count) + ' and a mean play count of ' + str(count/user_count_number[word]) \n",
        "     top += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User 1059637 has a total play count of 674412 and a mean play count of 1878\n",
            "User 2064012 has a total play count of 548427 and a mean play count of 9455\n",
            "User 2069337 has a total play count of 393515 and a mean play count of 1519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PPmzIQYfrFV"
      },
      "source": [
        "####  Splitting Data for Testing\n",
        "\n",
        "Use the [randomSplit](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) function to divide the data (`usersingerData`) into:\n",
        "* A training set, `trainData`, that will be used to train the model. This set should constitute 40% of the data.\n",
        "* A validation set, `validationData`, used to perform parameter tuning. This set should constitute 40% of the data.\n",
        "* A test set, `testData`, used for a final evaluation of the model. This set should constitute 20% of the data.\n",
        "\n",
        "Use a random seed value of 13. Since these datasets will be repeatedly used you will probably want to persist them in memory using the [cache](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.cache) function.\n",
        "\n",
        "In addition, print out the first 3 elements of each set as well as their sizes; if you created these sets correctly, your output should look as follows:\n",
        "```\n",
        "[(1059637, 1000049, 1), (1059637, 1000056, 1), (1059637, 1000113, 5)]\n",
        "[(1059637, 1000010, 238), (1059637, 1000062, 11), (1059637, 1000112, 423)]\n",
        "[(1059637, 1000094, 1), (1059637, 1000130, 19129), (1059637, 1000139, 4)]\n",
        "19817\n",
        "19633\n",
        "10031\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tDgmgy8frFa",
        "outputId": "73f3ef1f-ccdc-4bd9-a335-ee831e7aec0a"
      },
      "source": [
        "#Splitting the data into train, test and cross validation\n",
        "trainData, validationData, testData = usersingerData.randomSplit([4, 4, 2], 13)\n",
        "\n",
        "print trainData.take(3)\n",
        "print validationData.take(3)\n",
        "print testData.take(3)\n",
        "print trainData.count()\n",
        "print validationData.count()\n",
        "print testData.count()\n",
        "\n",
        "#Caching and creating ratings object\n",
        "trainData = trainData.map(lambda l: Rating(*l)).cache()\n",
        "validationData = validationData.map(lambda l: Rating(*l)).cache()\n",
        "testData = testData.map(lambda l: Rating(*l)).cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1059637, 1000049, 1), (1059637, 1000056, 1), (1059637, 1000113, 5)]\n",
            "[(1059637, 1000010, 238), (1059637, 1000062, 11), (1059637, 1000112, 423)]\n",
            "[(1059637, 1000094, 1), (1059637, 1000130, 19129), (1059637, 1000139, 4)]\n",
            "19817\n",
            "19633\n",
            "10031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EM4XFblfrFh"
      },
      "source": [
        "## The Prediction based Recommender Model\n",
        "\n",
        "For this project, we will train the model with implicit feedback. You can read more information about this from the collaborative filtering page: \n",
        "\n",
        "Therefore, we must first devise a way to evaluate models. Once we have a method for evaluation, we can run a parameter sweep, evaluate each combination of parameters on the validation data, and choose the optimal set of parameters. The parameters then can be used to make predictions on the test data.\n",
        "\n",
        "### Model Evaluation\n",
        "\n",
        "Although there may be several ways to evaluate a model, we will use a simple method here. Suppose we have a model and some dataset of *true* singer plays for a set of users. This model can be used to predict the top X singer recommendations for a user and these recommendations can be compared the singer that the user actually listened to (here, X will be the number of singer in the dataset of *true* singer plays). Then, the fraction of overlap between the top X predictions of the model and the X singer that the user actually listened to can be calculated. This process can be repeated for all users and an average value returned.\n",
        "\n",
        "For example, suppose a model predicted [1,2,4,8] as the top X=4 singer for a user. Suppose, that user actually listened to the singer [1,3,7,8]. Then, for this user, the model would have a score of 2/4=0.5. To get the overall score, this would be performed for all users, with the average returned.\n",
        "\n",
        "**NOTE: when using the model to predict the top-X singer for a user, do not include the singer listed with that user in the training data.**\n",
        "\n",
        "Name your function `modelEval` and have it take a model (the output of ALS.trainImplicit) and a dataset as input. For parameter tuning, the dataset parameter should be set to the validation data (`validationData`). After parameter tuning, the model can be evaluated on the test data (`testData`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elyD8fp5frFl"
      },
      "source": [
        "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
        "from collections import defaultdict\n",
        "\n",
        "#model evaluation function\n",
        "def modelEval(model, dataset):\n",
        "    global trainData\n",
        "    global allsingers\n",
        "    \n",
        "    #Getting nonTrainsingers for each user\n",
        "    usersingers = defaultdict(list)\n",
        "    \n",
        "    for data in trainData.collect():\n",
        "        usersingers[data[0]].append(data[1])\n",
        "        \n",
        "    cvList = []\n",
        "        \n",
        "    for key in usersingers.keys():\n",
        "        usersingers[key] = list(set(allsingers) - set(usersingers[key]))\n",
        "        for singer in usersingers[key]:\n",
        "            cvList.append((key, singer))\n",
        "    \n",
        "    #Creating user,nonTrainsingers RDD\n",
        "    cvData = sc.parallelize(cvList)\n",
        "    \n",
        "    userOriginal = dataset.map(lambda x:(x.user, (x.product, x.rating))).groupByKey().collect()\n",
        "    \n",
        "    #prediction on the user, nonTrainsingers RDD\n",
        "    predictions = model.predictAll(cvData)\n",
        "    userPredictions = predictions.map(lambda x:(x.user, (x.product, x.rating))).groupByKey().collect()\n",
        "    original = {}\n",
        "    predictions = {}\n",
        "    \n",
        "    #Getting top X singers for each user\n",
        "    for line in userOriginal:\n",
        "        original[line[0]] = sorted(line[1], key=lambda x:x[1], reverse = True)\n",
        "        \n",
        "    for line in userPredictions:\n",
        "        predictions[line[0]] = sorted(line[1], key=lambda x:x[1], reverse = True)\n",
        "        \n",
        "    similarity = []\n",
        "    \n",
        "    for key in userOriginal:\n",
        "        similar = 0.0\n",
        "        \n",
        "        pred = predictions[key[0]]\n",
        "        org = original[key[0]]\n",
        "            \n",
        "        for value in org:\n",
        "            for item in pred[0:len(org)]:\n",
        "                if (value[0] == item[0]):\n",
        "                    similar += 1\n",
        "                    break\n",
        "                    \n",
        "        #Similarity calculation        \n",
        "        similarity.append(float(similar/len(org)))        \n",
        "        \n",
        "    string = \"The model score for rank \" + str(rank) + \" is \" + str(float(sum(similarity)/len(similarity)))    \n",
        "    print string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FAAGWtafrFq"
      },
      "source": [
        "### Model Construction\n",
        "\n",
        "Now we can build the best model possibly using the validation set of data and the `modelEval` function. Although, there are a few parameters we could optimize, for the sake of time, we will just try a few different values for the [rank parameter] seed 345  Loop through the values [2, 10, 20] and figure out which one produces the highest scored based on your model evaluation function.\n",
        "\n",
        "Important: this procedure may take several minutes to run.\n",
        "\n",
        "For each rank value, print out the output of the `modelEval` function for that model. Your output should look as follows:\n",
        "```\n",
        "The model score for rank 2 is 0.090431\n",
        "The model score for rank 10 is 0.095294\n",
        "The model score for rank 20 is 0.090248\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX-wPxYdfrFu",
        "outputId": "acdf1679-f768-41a5-e4fa-d35d29cc75ea"
      },
      "source": [
        "#Model evaluation through different rank parameters\n",
        "rank_list = [2, 10, 20]\n",
        "\n",
        "for rank in rank_list:\n",
        "    model = ALS.trainImplicit(trainData, rank, seed=345)\n",
        "    modelEval(model,validationData)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model score for rank 2 is 0.0909391661474\n",
            "The model score for rank 10 is 0.0957125879247\n",
            "The model score for rank 20 is 0.09047041725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej3pserUfrFz"
      },
      "source": [
        "Now, using the bestModel, we will check the results over the test data. Your result should be ~`0.0507`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5tdfMknfrF1",
        "outputId": "45efcb5f-98aa-4c11-d021-dbb82b8ff008"
      },
      "source": [
        "bestModel = ALS.trainImplicit(trainData, rank=10, seed=345)\n",
        "modelEval(bestModel, testData)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model score for rank 20 is 0.0512321818394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Sz0GH4frF3"
      },
      "source": [
        "## Trying Some singer Recommendations\n",
        "Using the best model above, predict the top 5 singer for user `1059637` using the [recommendProducts](http://spark.apache.org/docs/1.5.2/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.MatrixFactorizationModel.recommendProducts) function. Map the results (integer IDs) into the real singer name using `singerAlias`. Print the results. The output should look as follows:\n",
        "```\n",
        "singer 0: Brand New\n",
        "singer 1: Taking Back Sunday\n",
        "singer 2: Evanescence\n",
        "singer 3: Elliott Smith\n",
        "singer 4: blink-182\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohW4yh2ffrF6"
      },
      "source": [
        "ratings = bestModel.recommendProducts(1059637, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a19Q4m3frF8",
        "outputId": "5417f0c9-a9ad-4fb9-accb-a5537020c3e9"
      },
      "source": [
        "import re\n",
        "singer_data = singerData.collect()\n",
        "\n",
        "singer_names_dict = {}\n",
        "\n",
        "for line in singer_data:\n",
        "    pattern = re.match( r'(\\d+)(\\s+)(.*)', line)\n",
        "    singer_names_dict[str(pattern.group(1))] = pattern.group(3)\n",
        "\n",
        "for i in range(0,5):\n",
        "    if str(ratings[i].product) in singer_canonical_dict:\n",
        "        singer_id = singer_canonical_dict[str(ratings[i].product)]\n",
        "        print \"singer \" + str(i) + \": \"  + str(singer_names_dict[str(singer_id)])\n",
        "    else:\n",
        "        print \"singer \" + str(i) + \": \" + str(singer_names_dict[str(ratings[i].product)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artist 0: Brand New\n",
            "Artist 1: Taking Back Sunday\n",
            "Artist 2: Evanescence\n",
            "Artist 3: Elliott Smith\n",
            "Artist 4: blink-182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kd82qsJ6frGF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "62hxe3OefrGM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jCbMpp-0frGN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}